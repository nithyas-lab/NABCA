"""
COMPREHENSIVE SYSTEM VERIFICATION
Tests all key components and validates recent changes are working
"""
import psycopg2
import pandas as pd
import os
import json
from datetime import datetime

log_file = f"system_verification_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

def log_print(msg):
    print(msg)
    with open(log_file, 'a', encoding='utf-8') as f:
        f.write(msg + '\n')
        f.flush()

log_print("=" * 120)
log_print("COMPREHENSIVE SYSTEM VERIFICATION")
log_print("=" * 120)
log_print(f"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

# Test results tracker
all_tests = []

def test_result(test_name, passed, details=""):
    status = "PASS" if passed else "FAIL"
    all_tests.append({'test': test_name, 'status': status, 'details': details})
    symbol = "âœ“" if passed else "X"
    log_print(f"[{status}] {test_name}")
    if details:
        log_print(f"      {details}")

# Connect to database
try:
    conn = psycopg2.connect(
        host='db.tnricrwvrnsnfbvrvoor.supabase.co',
        port=5432,
        database='postgres',
        user='postgres',
        password='pkWEbDa5HkTSGV9j'
    )
    cur = conn.cursor()
    test_result("Database Connection", True, "Connected to Supabase")
except Exception as e:
    test_result("Database Connection", False, str(e))
    log_print("\nCANNOT PROCEED WITHOUT DATABASE CONNECTION")
    exit(1)

log_print("\n" + "=" * 120)
log_print("TEST 1: DATABASE STRUCTURE")
log_print("=" * 120 + "\n")

# Test 1.1: Check all expected tables exist
expected_tables = [
    'raw_ytd',
    'raw_rolling_12m',
    'raw_brand_summary',
    'raw_vendor_summary'
]

cur.execute("""
    SELECT table_name
    FROM information_schema.tables
    WHERE table_schema = 'new_nabca'
    ORDER BY table_name
""")
existing_tables = [row[0] for row in cur.fetchall()]

for table in expected_tables:
    exists = table in existing_tables
    test_result(f"Table exists: {table}", exists)

# Test 1.2: Check vendor_summary columns (recent changes)
cur.execute("""
    SELECT column_name
    FROM information_schema.columns
    WHERE table_schema = 'new_nabca'
    AND table_name = 'raw_vendor_summary'
    ORDER BY ordinal_position
""")
columns = [row[0] for row in cur.fetchall()]

# Check NULL columns were removed
removed_cols = ['l12m_pct_change', 'ytd_pct_change', 'curr_month_pct_change']
for col in removed_cols:
    test_result(f"NULL column removed: {col}", col not in columns)

# Check required columns exist
required_cols = ['vendor', 'brand', 'class', 'l12m_this_year', 'ytd_this_year',
                 'report_year', 'report_month']
for col in required_cols:
    test_result(f"Required column exists: {col}", col in columns)

log_print("\n" + "=" * 120)
log_print("TEST 2: DATA QUALITY (RECENT FIXES)")
log_print("=" * 120 + "\n")

# Test 2.1: No TOTAL VENDOR rows should exist
cur.execute("""
    SELECT COUNT(*)
    FROM new_nabca.raw_vendor_summary
    WHERE brand = 'TOTAL VENDOR'
""")
total_vendor_count = cur.fetchone()[0]
test_result("TOTAL VENDOR rows removed", total_vendor_count == 0,
            f"Found {total_vendor_count} rows (should be 0)")

# Test 2.2: No merged TOTAL VENDOR in brand names
cur.execute("""
    SELECT COUNT(*)
    FROM new_nabca.raw_vendor_summary
    WHERE brand LIKE '%TOTAL VENDOR%'
""")
merged_count = cur.fetchone()[0]
test_result("Merged TOTAL VENDOR cleaned", merged_count == 0,
            f"Found {merged_count} rows (should be 0)")

# Test 2.3: Duplicated class names should be reduced
cur.execute("""
    SELECT COUNT(*)
    FROM new_nabca.raw_vendor_summary
    WHERE class LIKE '%DOM DOM%'
    OR class LIKE '%WHSKY WHSKY%'
    OR class LIKE '%VODKA VODKA%'
""")
dup_count = cur.fetchone()[0]
test_result("Duplicated class names fixed", dup_count < 200,
            f"Found {dup_count} remaining (should be < 200, was 505)")

# Test 2.4: All 18 months present
cur.execute("""
    SELECT COUNT(DISTINCT (report_year, report_month))
    FROM new_nabca.raw_vendor_summary
""")
month_count = cur.fetchone()[0]
test_result("All 18 months uploaded", month_count == 18,
            f"Found {month_count} months")

# Test 2.5: Record counts per month
cur.execute("""
    SELECT report_year, report_month, COUNT(*)
    FROM new_nabca.raw_vendor_summary
    GROUP BY report_year, report_month
    ORDER BY report_year, report_month
""")
month_counts = cur.fetchall()
all_months_valid = all(20000 <= count <= 30000 for _, _, count in month_counts)
test_result("Monthly record counts valid", all_months_valid,
            f"Range: {min(c[2] for c in month_counts):,} - {max(c[2] for c in month_counts):,} records")

log_print("\n" + "=" * 120)
log_print("TEST 3: DATA INTEGRITY")
log_print("=" * 120 + "\n")

# Test 3.1: No duplicate records
cur.execute("""
    SELECT COUNT(*) FROM (
        SELECT vendor, brand, class, report_year, report_month, COUNT(*)
        FROM new_nabca.raw_vendor_summary
        GROUP BY vendor, brand, class, report_year, report_month
        HAVING COUNT(*) > 1
    ) dups
""")
dup_records = cur.fetchone()[0]
test_result("No duplicate records", dup_records == 0,
            f"Found {dup_records} duplicate groups")

# Test 3.2: Reasonable data ranges
cur.execute("""
    SELECT
        COUNT(*) as total,
        COUNT(CASE WHEN l12m_this_year < 0 THEN 1 END) as negative_l12m,
        COUNT(CASE WHEN ytd_this_year < 0 THEN 1 END) as negative_ytd,
        COUNT(CASE WHEN class IS NULL THEN 1 END) as null_class
    FROM new_nabca.raw_vendor_summary
""")
total, neg_l12m, neg_ytd, null_cls = cur.fetchone()
test_result("No negative L12M values", neg_l12m == 0, f"Found {neg_l12m}")
test_result("No negative YTD values", neg_ytd == 0, f"Found {neg_ytd}")
test_result("NULL class values documented", null_cls <= 3500,
            f"Found {null_cls:,} NULL classes (expected ~3,290)")

log_print("\n" + "=" * 120)
log_print("TEST 4: FILE SYSTEM CHECK")
log_print("=" * 120 + "\n")

# Test 4.1: Check Excel files exist
output_dir = "output"
if os.path.exists(output_dir):
    excel_files = [f for f in os.listdir(output_dir) if f.startswith('vendor_summary_') and f.endswith('.xlsx')]
    test_result("Excel files present", len(excel_files) >= 18,
                f"Found {len(excel_files)} Excel files")
else:
    test_result("Excel files present", False, "output/ directory not found")

# Test 4.2: Check cache files exist
cache_dir = "cache"
if os.path.exists(cache_dir):
    cache_files = [f for f in os.listdir(cache_dir) if f.startswith('textract_vendor_summary_')]
    test_result("Cache files present", len(cache_files) >= 18,
                f"Found {len(cache_files)} cache files")
else:
    test_result("Cache files present", False, "cache/ directory not found")

# Test 4.3: Check validation reports exist
reports = [
    'VENDOR_SUMMARY_VALIDATION_REPORT.md',
    'VENDOR_SUMMARY_TRUE_ACCURACY_REPORT.md',
    'VALIDATION_SUMMARY.md'
]
base_dir = ".."
for report in reports:
    report_path = os.path.join(base_dir, report)
    exists = os.path.exists(report_path)
    test_result(f"Report exists: {report}", exists)

log_print("\n" + "=" * 120)
log_print("TEST 5: VALIDATION SCRIPTS")
log_print("=" * 120 + "\n")

# Test 5.1: Check key scripts exist
key_scripts = [
    'comprehensive_data_quality_scan.py',
    'vendor_summary_monthly_split.py',
    'fix_duplicated_class_names.py',
    'remove_total_vendor_rows.py',
    'fix_merged_total_vendor.py'
]

for script in key_scripts:
    exists = os.path.exists(script)
    test_result(f"Script exists: {script}", exists)

log_print("\n" + "=" * 120)
log_print("TEST 6: BRAND SUMMARY TABLE (COMPARISON)")
log_print("=" * 120 + "\n")

# Test 6.1: Brand summary record count
cur.execute("SELECT COUNT(*) FROM new_nabca.raw_brand_summary")
brand_count = cur.fetchone()[0]
test_result("Brand summary has data", brand_count > 400000,
            f"Found {brand_count:,} records")

# Test 6.2: Brand summary months
cur.execute("""
    SELECT COUNT(DISTINCT (report_year, report_month))
    FROM new_nabca.raw_brand_summary
""")
brand_months = cur.fetchone()[0]
test_result("Brand summary has 18 months", brand_months == 18,
            f"Found {brand_months} months")

log_print("\n" + "=" * 120)
log_print("TEST 7: ACCURACY METRICS")
log_print("=" * 120 + "\n")

# Test 7.1: Calculate current accuracy
cur.execute("""
    SELECT
        COUNT(*) as total,
        COUNT(CASE WHEN class LIKE '%% %%' AND (
            class LIKE '%%DOM DOM%%' OR
            class LIKE '%%WHSKY WHSKY%%'
        ) THEN 1 END) as dup_class,
        COUNT(CASE WHEN LENGTH(class) <= 5 AND class IS NOT NULL THEN 1 END) as trunc_class,
        COUNT(CASE WHEN class IS NULL THEN 1 END) as null_class
    FROM new_nabca.raw_vendor_summary
""")
total, dup_cls, trunc_cls, null_cls = cur.fetchone()
total_errors = dup_cls + trunc_cls + null_cls
accuracy = ((total - total_errors) / total * 100) if total > 0 else 0

test_result("Accuracy >= 98%", accuracy >= 98.0,
            f"Current accuracy: {accuracy:.2f}% (errors: {total_errors:,})")

log_print("\n" + "=" * 120)
log_print("VERIFICATION SUMMARY")
log_print("=" * 120 + "\n")

total_tests = len(all_tests)
passed_tests = sum(1 for t in all_tests if t['status'] == 'PASS')
failed_tests = total_tests - passed_tests

log_print(f"Total Tests Run: {total_tests}")
log_print(f"Tests Passed: {passed_tests}")
log_print(f"Tests Failed: {failed_tests}")
log_print(f"Success Rate: {(passed_tests/total_tests*100):.1f}%\n")

if failed_tests > 0:
    log_print("Failed Tests:")
    for test in all_tests:
        if test['status'] == 'FAIL':
            log_print(f"  - {test['test']}")
            if test['details']:
                log_print(f"    {test['details']}")

log_print("\n" + "=" * 120)
log_print("READINESS ASSESSMENT")
log_print("=" * 120 + "\n")

if passed_tests == total_tests:
    log_print("STATUS: READY TO SHARE")
    log_print("\nAll systems verified and working correctly!")
    log_print("Recent changes are reflected in the database.")
    log_print("Documentation is up to date.")
    log_print("\nYou can confidently share:")
    log_print("  - Database connection details")
    log_print("  - Validation reports")
    log_print("  - Extraction scripts")
    log_print("  - Data quality metrics")
elif passed_tests >= total_tests * 0.9:
    log_print("STATUS: MOSTLY READY")
    log_print(f"\n{failed_tests} minor issues found but system is functional.")
    log_print("Review failed tests before sharing.")
else:
    log_print("STATUS: NOT READY")
    log_print(f"\n{failed_tests} issues found that should be addressed.")
    log_print("Fix failed tests before sharing with others.")

log_print(f"\n\nVerification log saved to: {log_file}")
log_print("=" * 120)

cur.close()
conn.close()
